{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "760f3953",
   "metadata": {},
   "source": [
    "# Scene similarity experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84760be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from cv2 import VideoCapture\n",
    "from scenedetect import ContentDetector, SceneManager, open_video\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), \"..\"))\n",
    "from scene_detector.fingerprint import fingerprint_distance\n",
    "\n",
    "video_path = Path(os.getcwd()).parent.parent.parent / \"movies\" / \"pizza-conversation.mp4\"\n",
    "cap = VideoCapture(video_path)\n",
    "\n",
    "scene_manager = SceneManager()\n",
    "scene_manager.add_detector(ContentDetector(threshold=30.0, min_scene_len=2))\n",
    "\n",
    "# Perform scene detection\n",
    "scene_manager.detect_scenes(open_video(str(video_path)))\n",
    "\n",
    "# Get list of scene boundaries (list of (start_time, end_time))\n",
    "scene_list = scene_manager.get_scene_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f343b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(str(video_path))\n",
    "\n",
    "scene_keypoints = []\n",
    "for start, end in scene_list:\n",
    "    start_sec = start.get_seconds()\n",
    "    end_sec = end.get_seconds()\n",
    "\n",
    "    # Seek to midpoint frame of the scene to extract keyframe\n",
    "    mid_sec = (start_sec + end_sec) / 2\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, mid_sec * 1000)\n",
    "    success, frame = cap.read()\n",
    "    scene_keypoints.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1765c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "scene_count = len(scene_list)\n",
    "\n",
    "scenes_per_row = 4\n",
    "rows = scene_count // scenes_per_row\n",
    "cols = scenes_per_row\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 2 * rows))\n",
    "for i, scene_keypoint in enumerate(scene_keypoints):\n",
    "    axes[i // cols, i % cols].imshow(cv2.cvtColor(scene_keypoint, cv2.COLOR_BGR2RGB))\n",
    "    axes[i // cols, i % cols].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ef732",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_image_hash(image_array, hash_func):\n",
    "    \"\"\"Calculate hash for a single image\"\"\"\n",
    "    try:\n",
    "        return hash_func(Image.fromarray(image_array))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def compare_two_images(img_path1, img_path2, hash_func):\n",
    "    \"\"\"Compare two specific images\"\"\"\n",
    "    hash1 = calculate_image_hash(img_path1, hash_func)\n",
    "    hash2 = calculate_image_hash(img_path2, hash_func)\n",
    "\n",
    "    if hash1 and hash2:\n",
    "        distance = hash1 - hash2\n",
    "        return distance\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c6857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagehash\n",
    "from PIL import Image\n",
    "\n",
    "hash_algorithms = {\n",
    "    \"average_hash\": imagehash.average_hash,\n",
    "    # 'perceptual_hash': imagehash.phash,\n",
    "    # 'difference_hash': imagehash.dhash,\n",
    "    \"wavelet_hash\": imagehash.whash,\n",
    "}\n",
    "\n",
    "\n",
    "for start, end in scene_list:\n",
    "    start_sec = start.get_seconds()\n",
    "    end_sec = end.get_seconds()\n",
    "\n",
    "    frames_seconds = np.linspace(start_sec, end_sec, 9)\n",
    "    frames_in_scene = []\n",
    "    mid_sec = (start_sec + end_sec) / 2\n",
    "    for frame_sec in frames_seconds:\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, frame_sec * 1000)\n",
    "        success, frame = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "        frames_in_scene.append(frame)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_MSEC, mid_sec * 1000)\n",
    "    success, reference_frame = cap.read()\n",
    "\n",
    "    fig, axes = plt.subplots(len(hash_algorithms), len(frames_in_scene), figsize=(20, 10), tight_layout=True)\n",
    "\n",
    "    for row, (hash_name, hash_func) in enumerate(hash_algorithms.items()):\n",
    "\n",
    "        def f(frame):\n",
    "            return str(hash_func(Image.fromarray(frame), hash_size=32))\n",
    "\n",
    "        reference_fingerprint = f(reference_frame)\n",
    "\n",
    "        for i, (second, frame) in enumerate(zip(frames_seconds, frames_in_scene, strict=False)):\n",
    "            fingerprint = f(frame)\n",
    "            distance = fingerprint_distance(reference_fingerprint, fingerprint)\n",
    "\n",
    "            axes[row][i].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "            axes[row][i].axis(\"off\")\n",
    "            reference_point = abs(mid_sec - second) < 0.1\n",
    "            axes[row][i].set_title(f\"{second:.2f}s\" + (\"*\" if reference_point else \"\") + f\" {hash_name}\\n{distance}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87165279",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
